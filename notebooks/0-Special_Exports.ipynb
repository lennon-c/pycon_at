{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addb73e3",
   "metadata": {},
   "source": [
    "The **Special Export** tool fetches specific pages with their raw content (*wikitext*) in real-time, without needing to download the entire dataset. The content is provided in XML format.\n",
    "\n",
    "\n",
    "\n",
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa253a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # to fetch info from URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3940d8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Using the **Special Export** Tool\n",
    "\n",
    "You can actually use **Special:Export** to retrieve pages from *any* Wiki site. On the German Wiktionary, however, the tool is labelled **Spezial:Exportieren**, but it works the same way.\n",
    "\n",
    "\n",
    "**Exporting Pages from Any Wiki Site**\n",
    "\n",
    "To access the XML content of the page titled \"Austria\" from English Wikipedia, you can construct your URL as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2dafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Austria'\n",
    "domain = 'en.wikipedia.org'\n",
    "url = f'https://{domain}/wiki/Special:Export/{title}'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dff8f4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Exporting Pages from the German Wiktionary**\n",
    "\n",
    "For the German Wiktionary, the export tool uses `Spezial:Exportieren` instead of `Special:Export`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21360f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'hoch'\n",
    "domain = 'de.wiktionary.org'\n",
    "url = f'https://{domain}/wiki/Spezial:Exportieren/{title}'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38c982",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Fetching XML Data with `requests`\n",
    "\n",
    "\n",
    "To programmatically fetch and download XML content, you can use Python's `requests` library. This example shows how to build the URL, make a request, and get the XML content of a Wiktionary page by its title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98019e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(title):\n",
    "    # Construct the URL for the XML export of the given page title\n",
    "    url = f'https://de.wiktionary.org/wiki/Spezial:Exportieren/{title}'\n",
    "    \n",
    "    # Send a GET request\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful, and raise an error if not\n",
    "    resp.raise_for_status()\n",
    "    \n",
    "    # Return the XML content of the requested page\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5302367",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Next, let us attempt to retrieve the XML content for the page titled \"hoch\" and print the initial 500 bytes for a glimpse of the XML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = fetch('hoch')\n",
    "print(page[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e6447",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We will continue to use the `fetch` function throughout this tutorial.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
